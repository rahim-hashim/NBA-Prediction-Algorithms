{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"basketball-reference-scraper.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1kRsyUx7A3hl"},"source":["# Basketball-Reference Scraper Overview\n","The following code will walk you through how to scrape NBA player and game data from www.basketball-reference.com and input it into a Pandas database. In other scripts within this directory, we will be using the data captured here to run analyses that will help the average user ask both broad and specific questions related to the NBA. We will probe on what statistics and criteria are important for an NBA team to win an NBA championship, how the league has evolved year-over-year, touch on the GOAT debate, and ultimately, build algorithms that can (hopefully) help us all beat Vegas lines consistently so that we can all retire from our day jobs and gamble on the NBA for the rest of our careers. \n","\n","None of this could have been done without the tireless and comprehensive effort of those who work at [Basketball Reference](http://www.basketball-reference.com) providing an open-source, API-friendly database containing millions of datapoints from which the entirety of this codebase is built. \n","\n","For any questions/concerns, feel free to reach out to me directly at rahim.hashim@columbia.edu. And in the case that this is useful to anyone for future projects, please give credit where credit is due, both to [Basketball Reference](http://www.basketball-reference.com) and myself. Enjoy!"]},{"cell_type":"markdown","metadata":{"id":"OB4Sr3HrA3ho"},"source":["***\n","## The Basics\n","__Jupyter Notebook__: All of the following code is hosted in a Python 3 Jupyter Notebook. It is recommended to use Anaconda to access the Notebook in order to have synchronously have access to all Python Libraries used in the rest of the code. \n","\n","In order to execute and compile code in the notebook, go to the desired code box and press _Shift_ + _Enter_ at the same time. All code below is recommended to be executed from top to bottom in order.\n","\n","__Python Libraries__: Python is a beautiful language for a number of reasons, one of which is it's immense\n","amount of pre-built libraries that do much of the heavy lifting in any web-scraping /\n","data analysis project. When getting familiar with Python and starting a new project, be\n","sure to look through the internet for a Python library that may help. A comprehensive list\n","that I often refer to before starting a project is here: [https://github.com/vinta/awesome-python](https://github.com/vinta/awesome-python)\n","\n","__Installing Libraries__: In case you receive an error upon trying to execute the following box, such as _ModuleNotFoundError: No module named 'numpy'_, go back to your terminal and open a new tab, and install the library using pip: _pip install numpy_"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XTjEEkBUA3hp","executionInfo":{"status":"ok","timestamp":1633007720134,"user_tz":240,"elapsed":18552,"user":{"displayName":"Rahim Hashim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii5Vx-Cqt2GJJaJooA1bsVritGDY0Nk_5cvblXdQ=s64","userId":"11331866492875815263"}},"outputId":"f1f5008e-4d90-4ad6-969f-87478f5470c5"},"source":["%reload_ext autoreload\n","import os\n","import sys\n","import numpy as np\n","import pandas as pd\n","from pprint import pprint\n","import matplotlib.pyplot as plt\n","from collections import Counter, OrderedDict, defaultdict\n","pd.options.mode.chained_assignment = None  # default='warn'\n","\n","ROOT = '/content/drive/MyDrive/Projects/nba-prediction-algorithm/NBA-Prediction-Algorithms/' #@param ['/content/drive/MyDrive/Projects/nba-prediction-algorithm/NBA-Prediction-Algorithms/']  \n","\n","# add (non-Python) helper functions\n","def add_helpers():\n","  '''\n","  add_helper mounts google drive and adds\n","  helper functions to the sys.path\n","  '''\n","\n","  # if running on juypter/google colab, mount to google drive\n","  if 'google.colab' in str(get_ipython()): \n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    os.chdir(ROOT)\n","\n","  helper_dir_path = ROOT + 'helper/'\n","  print('\\nHelpers:')\n","  pprint(sorted(os.listdir(helper_dir_path)))\n","  sys.path.append(helper_dir_path) # set to path of notebook\n","\n","add_helpers()"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\n","Helpers:\n","['Regions.py',\n"," 'TeamNames.py',\n"," '__pycache__',\n"," 'bettingLinesScraper.py',\n"," 'fuzzy_lookup.py',\n"," 'game_log_scraper.py',\n"," 'gamelog_scraper_openai.ipynb',\n"," 'gamelogscraper.ipynb',\n"," 'meta_info_scraper.py',\n"," 'player_info_scraper.py',\n"," 'player_scraper.py',\n"," 'player_table_scraper.py',\n"," 'recordDateScraper.py',\n"," 'teamsScraper.py']\n"]}]},{"cell_type":"markdown","metadata":{"id":"fA_4SZZ_A3hy"},"source":["***\n","## Creating Databases\n","Pandas databases are a powerful tool to query large amounts of data, as we will be doing here. For that reason, we are going to insert all of the data scraped above into a Pandas database. The below code will take player overview data from playerHash and insert it into player_df<br>\n",">For documentation on pandas: https://pypi.org/project/pandas/"]},{"cell_type":"code","metadata":{"id":"gzw182HVki6V","executionInfo":{"status":"ok","timestamp":1633007720137,"user_tz":240,"elapsed":12,"user":{"displayName":"Rahim Hashim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii5Vx-Cqt2GJJaJooA1bsVritGDY0Nk_5cvblXdQ=s64","userId":"11331866492875815263"}}},"source":["DATA_PATH = ROOT + 'data/'"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DjOz4WduA3hr"},"source":["***\n","## Scraping Player Data\n","### Biometrics and season + career statistics\n","\n","playerScraper and metaDataScraper will be doing most of the work to scrape data on each player's background and physical attributes.<br>\n","> Example Overview Source (last name starting with a): https://www.basketball-reference.com/players/a/<br>\n","> Example meta-data (Karim Abdul-Jabbar): https://www.basketball-reference.com/players/a/abdulka01.html<br>\n","> For documentation on requests(): https://realpython.com/python-requests/<br>\n","> For documentation on BeautifulSoup: https://www.crummy.com/software/BeautifulSoup/bs4/doc/"]},{"cell_type":"markdown","metadata":{"id":"k6fDwyaYA3hs"},"source":["___Time Estimates:___ This is the most computationally-intensive function in the program, requiring many url requests in order to complete.<br>\n",">*Without threading:* ~1hr<br>\n",">*With threading:* ~15min<br>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"id":"yh5t1y4eA3ht","executionInfo":{"status":"error","timestamp":1633007735169,"user_tz":240,"elapsed":15041,"user":{"displayName":"Rahim Hashim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii5Vx-Cqt2GJJaJooA1bsVritGDY0Nk_5cvblXdQ=s64","userId":"11331866492875815263"}},"outputId":"fd6a0bb6-661f-4177-d651-9ac435b19be2"},"source":["from player_scraper import scrape_all_players\n","\n","list_players_meta, list_players_data, list_players_gamelogs = scrape_all_players(ROOT, THREAD_FLAG=True)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["players_df_meta.pkl already exists\n","  Uploading...\n","players_df_data.pkl already exists\n","  Uploading...\n","players_df_gamelogs.pkl already exists\n","  Uploading...\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-1acd56f8de47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplayer_scraper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscrape_all_players\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlist_players_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_players_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_players_gamelogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_all_players\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTHREAD_FLAG\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"]}]},{"cell_type":"markdown","metadata":{"id":"tEZg_HErTusP"},"source":["***\n","## Concatenating Player Data\n","\n","Now that all the individual players' bio data, season-wide stats, and gamelogs have  been captured, they can be concatenated to generate 3 DataFrames holding all the players. "]},{"cell_type":"code","metadata":{"id":"0-ApJBSmTmv0","executionInfo":{"status":"aborted","timestamp":1633007735166,"user_tz":240,"elapsed":5,"user":{"displayName":"Rahim Hashim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii5Vx-Cqt2GJJaJooA1bsVritGDY0Nk_5cvblXdQ=s64","userId":"11331866492875815263"}}},"source":["from player_scraper import concatenate_dfs\n","df_players_meta, df_players_data, df_players_gamelogs = concatenate_dfs(ROOT, list_players_meta, list_players_data, list_players_gamelogs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j6tq7GHNA3h3"},"source":["***\n","## Example Queries (Simple)\n","\n","The following are example queries we can make across all of the generated tables. As can be seen below, the structure of the DataFrame allows for immense flexibility and speed gains as compared to looking at the website itself. We will utilize this structure for more specific trend-, team-, and era- related investigations."]},{"cell_type":"code","metadata":{"id":"2pBGwkXDsehc","executionInfo":{"status":"aborted","timestamp":1633007735167,"user_tz":240,"elapsed":6,"user":{"displayName":"Rahim Hashim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii5Vx-Cqt2GJJaJooA1bsVritGDY0Nk_5cvblXdQ=s64","userId":"11331866492875815263"}}},"source":["df_players_meta.head(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezPHci3py09H","executionInfo":{"status":"aborted","timestamp":1633007735167,"user_tz":240,"elapsed":6,"user":{"displayName":"Rahim Hashim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii5Vx-Cqt2GJJaJooA1bsVritGDY0Nk_5cvblXdQ=s64","userId":"11331866492875815263"}}},"source":["# Player Meta Query\n","df_large = df_players_meta.loc[(df_players_meta['height']>80) & \n","                   (df_players_meta['weight']>30)]\n","\n","df_large = df_large.dropna(how='all', axis='columns') # drops all columns that are empty\n","display(df_large[df_large['weight'] == df_large['weight'].max()])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"shq2nKDYuxM1","executionInfo":{"status":"aborted","timestamp":1633007735168,"user_tz":240,"elapsed":7,"user":{"displayName":"Rahim Hashim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii5Vx-Cqt2GJJaJooA1bsVritGDY0Nk_5cvblXdQ=s64","userId":"11331866492875815263"}}},"source":["df_players_data.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LPysQbwXCa0A","executionInfo":{"status":"aborted","timestamp":1633007735168,"user_tz":240,"elapsed":7,"user":{"displayName":"Rahim Hashim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii5Vx-Cqt2GJJaJooA1bsVritGDY0Nk_5cvblXdQ=s64","userId":"11331866492875815263"}}},"source":["# Player Data Query\n","'''\n","df_career = df_players_data.loc[(df_players_data['season']=='Career') & \n","                   (df_players_data['season_playoffs']=='season') &\n","                   (df_players_data['data_type']=='advanced')]\n","'''\n","df_players_data['mp_clean'] = df_players_data['mp_per_g'].apply(float)\n","#df_career[df_career['ws_per_48'].notna()].sort_values('ws_per_48', ascending=False)\n","df_players_data[(df_players_data['season'] == '2020-21') & \n","                (df_players_data['data_type'] == 'per_game') &\n","                (df_players_data['mp_clean'] > 40)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJ1JZCrs0Klk","executionInfo":{"status":"aborted","timestamp":1633007735169,"user_tz":240,"elapsed":7,"user":{"displayName":"Rahim Hashim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii5Vx-Cqt2GJJaJooA1bsVritGDY0Nk_5cvblXdQ=s64","userId":"11331866492875815263"}}},"source":["df_players_gamelogs.head(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9PNTy4Xb0eGs","executionInfo":{"status":"aborted","timestamp":1633007735169,"user_tz":240,"elapsed":7,"user":{"displayName":"Rahim Hashim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii5Vx-Cqt2GJJaJooA1bsVritGDY0Nk_5cvblXdQ=s64","userId":"11331866492875815263"}}},"source":["df_players_gamelogs.head(5)"],"execution_count":null,"outputs":[]}]}