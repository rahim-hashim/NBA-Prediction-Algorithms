{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"basketball-reference-scraper.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1kRsyUx7A3hl"},"source":["# Basketball-Reference Scraper Overview\n","The following code will walk you through how to scrape NBA player and game data from www.basketball-reference.com and input it into a Pandas database. In other scripts within this directory, we will be using the data captured here to run analyses that will help the average user ask both broad and specific questions related to the NBA. We will probe on what statistics and criteria are important for an NBA team to win an NBA championship, how the league has evolved year-over-year, touch on the GOAT debate, and ultimately, build algorithms that can (hopefully) help us all beat Vegas lines consistently so that we can all retire from our day jobs and gamble on the NBA for the rest of our careers. \n","\n","None of this could have been done without the tireless and comprehensive effort of those who work at [Basketball Reference](http://www.basketball-reference.com) providing an open-source, API-friendly database containing millions of datapoints from which the entirety of this codebase is built. \n","\n","For any questions/concerns, feel free to reach out to me directly at rahim.hashim@columbia.edu. And in the case that this is useful to anyone for future projects, please give credit where credit is due, both to [Basketball Reference](http://www.basketball-reference.com) and myself. Enjoy!"]},{"cell_type":"markdown","metadata":{"id":"OB4Sr3HrA3ho"},"source":["***\n","## The Basics\n","__Jupyter Notebook__: All of the following code is hosted in a Python 3 Jupyter Notebook. It is recommended to use Anaconda to access the Notebook in order to have synchronously have access to all Python Libraries used in the rest of the code. \n","\n","In order to execute and compile code in the notebook, go to the desired code box and press _Shift_ + _Enter_ at the same time. All code below is recommended to be executed from top to bottom in order.\n","\n","__Python Libraries__: Python is a beautiful language for a number of reasons, one of which is it's immense\n","amount of pre-built libraries that do much of the heavy lifting in any web-scraping /\n","data analysis project. When getting familiar with Python and starting a new project, be\n","sure to look through the internet for a Python library that may help. A comprehensive list\n","that I often refer to before starting a project is here: [https://github.com/vinta/awesome-python](https://github.com/vinta/awesome-python)\n","\n","__Installing Libraries__: In case you receive an error upon trying to execute the following box, such as _ModuleNotFoundError: No module named 'numpy'_, go back to your terminal and open a new tab, and install the library using pip: _pip install numpy_"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XTjEEkBUA3hp","executionInfo":{"status":"ok","timestamp":1632856388811,"user_tz":240,"elapsed":1357,"user":{"displayName":"Rahim Hashim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii5Vx-Cqt2GJJaJooA1bsVritGDY0Nk_5cvblXdQ=s64","userId":"11331866492875815263"}},"outputId":"70328614-d172-4174-bd26-fe53a2f059cb"},"source":["%reload_ext autoreload\n","import re\n","import os\n","import sys\n","import numpy as np\n","import pandas as pd\n","from pprint import pprint\n","from bs4 import BeautifulSoup\n","import matplotlib.pyplot as plt\n","from collections import Counter, OrderedDict, defaultdict\n","pd.options.mode.chained_assignment = None  # default='warn'\n","\n","ROOT = '/content/drive/MyDrive/Projects/nba-prediction-algorithm/NBA-Prediction-Algorithms/'\n","\n","# add (non-Python) helper functions\n","def add_helpers():\n","  '''\n","  add_helper mounts google drive and adds\n","  helper functions to the sys.path\n","  '''\n","\n","  # if running on juypter/google colab, mount to google drive\n","  if 'google.colab' in str(get_ipython()): \n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    %cd drive/MyDrive/Projects/nba-prediction-algorithm/NBA-Prediction-Algorithms/\n","\n","  helper_dir_path = ROOT + 'helper/'\n","  print('\\nHelpers:')\n","  pprint(sorted(os.listdir(helper_dir_path)))\n","  sys.path.append(helper_dir_path) # set to path of notebook\n","\n","add_helpers()"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Projects/nba-prediction-algorithm/NBA-Prediction-Algorithms\n","\n","Helpers:\n","['Regions.py',\n"," 'TeamNames.py',\n"," '__pycache__',\n"," 'bettingLinesScraper.py',\n"," 'fuzzy_lookup.py',\n"," 'game_log_scraper.py',\n"," 'gamelog_scraper_openai.ipynb',\n"," 'gamelogscraper.ipynb',\n"," 'meta_info_scraper.py',\n"," 'player_info_scraper.py',\n"," 'player_scraper.py',\n"," 'player_table_scraper.py',\n"," 'recordDateScraper.py',\n"," 'teamsScraper.py']\n"]}]},{"cell_type":"markdown","metadata":{"id":"fA_4SZZ_A3hy"},"source":["***\n","## Creating Databases\n","Pandas databases are a powerful tool to query large amounts of data, as we will be doing here. For that reason, we are going to insert all of the data scraped above into a Pandas database. The below code will take player overview data from playerHash and insert it into player_df<br>\n",">For documentation on pandas: https://pypi.org/project/pandas/"]},{"cell_type":"markdown","metadata":{"id":"DjOz4WduA3hr"},"source":["***\n","## Scraping Player Data\n","### Biometrics and season + career statistics\n","\n","playerScraper and metaDataScraper will be doing most of the work to scrape data on each player's background and physical attributes.<br>\n","> Example Overview Source (last name starting with a): https://www.basketball-reference.com/players/a/<br>\n","> Example meta-data (Karim Abdul-Jabbar): https://www.basketball-reference.com/players/a/abdulka01.html<br>\n","> For documentation on requests(): https://realpython.com/python-requests/<br>\n","> For documentation on BeautifulSoup: https://www.crummy.com/software/BeautifulSoup/bs4/doc/"]},{"cell_type":"markdown","metadata":{"id":"k6fDwyaYA3hs"},"source":["___Time Estimates:___ This is the most computationally-intensive function in the program, requiring many url requests in order to complete.<br>\n",">*Without threading:* ~1hr<br>\n",">*With threading:* ~15min<br>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yh5t1y4eA3ht","outputId":"e0bef38d-b871-4f47-90fe-e5bd67df4344"},"source":["from player_scraper import scrape_all_players\n","\n","ROOT = '/content/drive/MyDrive/Projects/nba-prediction-algorithm/NBA-Prediction-Algorithms/'\n","df_players_meta, df_players_data, df_players_gamelogs = scrape_all_players(ROOT, THREAD_FLAG=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running meta_info_scraper.py\n","  Start Time: 19:13:09.61\n","  Threading inactivated...\n"]}]},{"cell_type":"markdown","metadata":{"id":"j6tq7GHNA3h3"},"source":["***\n","## Example Queries (Simple)\n","\n","The following are example queries we can make across all of the generated tables. As can be seen below, the structure of the DataFrame allows for immense flexibility and speed gains as compared to looking at the website itself. We will utilize this structure for more specific trend-, team-, and era- related investigations."]},{"cell_type":"code","metadata":{"id":"2pBGwkXDsehc"},"source":["df_players_meta.head(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezPHci3py09H"},"source":["# Player Meta Query\n","df_large = df_players_meta.loc[(df_players_meta['height']>80) & \n","                   (df_players_meta['weight']>30)]\n","\n","df_large = df_large.dropna(how='all', axis='columns') # drops all columns that are empty\n","display(df_large[df_large['weight'] == df_large['weight'].max()])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"shq2nKDYuxM1"},"source":["df_players_data.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LPysQbwXCa0A"},"source":["# Player Data Query\n","'''\n","df_career = df_players_data.loc[(df_players_data['season']=='Career') & \n","                   (df_players_data['season_playoffs']=='season') &\n","                   (df_players_data['data_type']=='advanced')]\n","'''\n","df_players_data['mp_clean'] = df_players_data['mp_per_g'].apply(float)\n","#df_career[df_career['ws_per_48'].notna()].sort_values('ws_per_48', ascending=False)\n","df_players_data[(df_players_data['season'] == '2020-21') & \n","                (df_players_data['data_type'] == 'per_game') &\n","                (df_players_data['mp_clean'] > 40)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJ1JZCrs0Klk"},"source":["df_players_gamelogs.head(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9PNTy4Xb0eGs"},"source":["df_players_gamelogs.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MSAFd35uqVE-"},"source":["***\n","## Single Player Queries\n","\n","If you don't need to scrape the entire basketball-reference website but instead just want information for one player, you can use the following command."]},{"cell_type":"code","metadata":{"id":"ztDDSN48qSjO"},"source":["from player_scraper import single_player_scraper\n","\n","pd.set_option('display.max_rows', None)\n","single_player_info, single_player_df, single_player_gl = single_player_scraper()\n","single_player_df.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xefPghxAA3hv"},"source":["***\n","## Scraping Game Data\n","### Game-logs and team statistics"]},{"cell_type":"code","metadata":{"id":"Mf63l4SZA3hv"},"source":["single_player_gl"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"etaT6ZgWA3hw"},"source":["***\n","## Data Organization\n","To help us understand how all the data is organized, here's a visual:"]},{"cell_type":"code","metadata":{"id":"ewk1N94sA3hw"},"source":["df_career = df_players_data.loc[(df_players_data['season']=='Career') & \n","                   (df_players_data['season_playoffs']=='season') &\n","                   (df_players_data['data_type']=='advanced')]\n","\n","df_career.dropna(axis='columns')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kYWAsSG7A3hx"},"source":["***\n","## Meta-Data Analysis\n","Now that we've scraped all the meta-info on each player, we can start running analyses.\n","\n","Below, a few simple analyses are included to help you get started. The first set of graphs examine height distribution (left), weight distribution (middle), and shooting handedness (right)."]},{"cell_type":"code","metadata":{"id":"RMkAgQ-BA3hx","scrolled":true},"source":["from Regions import stateDict #stateDict is a Dictionary to help with geography-based analyses\n","def metaPlot():\n","  \n","  height_list = df_players_meta['height'].tolist()\n","  weight_list = df_players_meta['weight'].tolist()\n","  #rightCount = 0; leftCount = 0; noHandCount = 0\n","\n","  #Plot Height Distribution (1, Left)\n","  f, ax = plt.subplots(1,2)\n","  #Sets default plot size\n","  plt.rcParams['figure.figsize'] = (10,8)\n","  n1, bins1, patches1 = ax[0].hist(height_list, bins=20, density=True, histtype='bar', ec='black')\n","  #Converting y-axis labels from decimals to percents\n","  y_vals = ax[0].get_yticks(); ax[0].set_yticklabels(['{:3.1f}%'.format(y*100) for y in y_vals])\n","  #Converting x-axis labels from inches back to feet\n","  xticks1 = ['5-0', '5-6', '6-0', '6-6', '7-0', '7-6', '8-0']\n","  ax[0].set_xticks([60, 66, 72, 78, 84, 90, 96])\n","  ax[0].set_xticklabels(xticks1)\n","  ax[0].set_xlim([56,100])\n","  ax[0].set_xlabel('Height', fontweight='bold', labelpad=10)\n","  ax[0].set_ylabel('Percent of Players', fontweight='bold', labelpad=10)\n","\n","  #Plot Weight Distribution (1, Middle)\n","  ax[1].hist(weight_list, bins='auto', density=True, histtype='bar', ec='black')\n","  y_vals = ax[1].get_yticks()\n","  ax[1].set_yticklabels(['{:3.1f}%'.format(y*100) for y in y_vals])\n","  xticks2 = ['150', '180', '210', '240', '270', '300', '330']\n","  ax[1].set_xticks([150, 180, 210, 240, 270, 300, 330])\n","  ax[1].set_xticklabels(xticks2)\n","  ax[1].set_xlim([120,360])\n","  ax[1].set_xlabel('Weight', fontweight='bold', labelpad=10)\n","  ax[1].set_ylabel('Percent of Players', fontweight='bold', labelpad=10)\n","  \n","  plt.tight_layout(pad=0.05, w_pad=4, h_pad=1.0)\n","  f.set_size_inches(18.5, 10.5, forward=True)\n","  plt.show()\n","        \n","metaPlot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NnmVzOKZA3hy"},"source":["def geographyPlot():\n","  countryList = df_players_meta['birthCountry'].tolist()\n","  #countryList contains all players born in ex-US\n","  countryList = filter(lambda x: x != 'United States of America', countryList)\n","  countryList = filter(lambda x: x != '', countryList)\n","  countryHash = dict(Counter(countryList))\n","  countryHash = OrderedDict(sorted(countryHash.items(), reverse=True, key=lambda t: t[1]))\n","\n","  pprint(countryHash.keys())\n","\n","  #Plot Birth Countries of non-US-Born Players (3)\n","  f, ax = plt.subplots(1)\n","  countryList = countryHash.keys(); countryVals = countryHash.values()\n","  ax.bar(np.arange(len(countryList)), countryVals, ec='black')\n","  ax.set_xticks(np.arange(len(countryList)))\n","  ax.set_xticklabels(countryList, rotation=90, ha='right', fontsize=7)\n","  ax.set_xlabel('Country of Birth', fontweight='bold', labelpad=10)\n","  ax.set_ylabel('Number of Players', fontweight='bold', labelpad=10)\n","  \n","  f.set_size_inches(18.5, 10.5, forward=True)\n","  plt.show()\n","    \n","geographyPlot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3KUaqisfT9Xd"},"source":[""],"execution_count":null,"outputs":[]}]}