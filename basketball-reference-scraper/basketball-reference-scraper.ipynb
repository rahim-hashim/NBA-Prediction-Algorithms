{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basketball-Reference Scraper Overview\n",
    "The following code will walk you through how to scrape NBA player and game data from www.basketball-reference.com and input it into a Pandas database. In other scripts within this directory, we will be using the data captured here to run analyses that will help the average user ask both broad and specific questions related to the NBA. We will probe on what statistics and criteria are important for an NBA team to win an NBA championship, how the league has evolved year-over-year, touch on the GOAT debate, and ultimately, build algorithms that can (hopefully) help us all beat Vegas lines consistently so that we can all retire from our day jobs and gamble on the NBA for the rest of our careers. \n",
    "\n",
    "None of this could have been done without the tireless and comprehensive effort of those who work at [Basketball Reference](http://www.basketball-reference.com) providing an open-source, API-friendly database containing millions of datapoints from which the entirety of this codebase is built. \n",
    "\n",
    "For any questions/concerns, feel free to reach out to me directly at rahim.hashim@columbia.edu. And in the case that this is useful to anyone for future projects, please give credit where credit is due, both to [Basketball Reference](http://www.basketball-reference.com) and myself. Enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## The Basics\n",
    "__Jupyter Notebook__: All of the following code is hosted in a Python 3 Jupyter Notebook. It is recommended to use Anaconda to access the Notebook in order to have synchronously have access to all Python Libraries used in the rest of the code. \n",
    "\n",
    "In order to execute and compile code in the notebook, go to the desired code box and press _Shift_ + _Enter_ at the same time. All code below is recommended to be executed from top to bottom in order.\n",
    "\n",
    "__Python Libraries__: Python is a beautiful language for a number of reasons, one of which is it's immense\n",
    "amount of pre-built libraries that do much of the heavy lifting in any web-scraping /\n",
    "data analysis project. When getting familiar with Python and starting a new project, be\n",
    "sure to look through the internet for a Python library that may help. A comprehensive list\n",
    "that I often refer to before starting a project is here: [https://github.com/vinta/awesome-python](https://github.com/vinta/awesome-python)\n",
    "\n",
    "__Installing Libraries__: In case you receive an error upon trying to execute the following box, such as _ModuleNotFoundError: No module named 'numpy'_, go back to your terminal and open a new tab, and install the library using pip: _pip install numpy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import threading\n",
    "import importlib\n",
    "import numpy as np\n",
    "from timeit import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "from string import ascii_lowercase\n",
    "\n",
    "#(Non-Python Library)\n",
    "#stateDict is a Dictionary that I created to help with geography-based analyses\n",
    "from Regions import stateDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Class Instantiation\n",
    "Another reason why Python is awesome is it's easy-to-use object-oriented programming. \n",
    "In case you aren't familiar with object oriented programming - _Classes_ and \n",
    "_Objects_ are the two main aspects of object oriented programming. A class creates a \n",
    "new unique and malleable type (e.g. int, string, list) with user-designated attributes. Objects are simply instances of the class. \n",
    "\n",
    "Here, the __Player__ class, __BasicStats__ class, __AdvancedStats__ class, __ShootingStats__ class, and __PlayByPlayStats__ class are initiated (from playerStatObjects), with defined attributes (e.g. name, draftYear...).\n",
    "Once we scrape www.basketball-reference.com, we will create type-specific objects that will each have the following attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PlayerStatObjects import Player, BasicStats, AdvancedStats, ShootingStats, PlayByPlayStats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Scraping Player Data\n",
    "### Biometrics and season + career statistics\n",
    "\n",
    "playerScraper and metaDataScraper will be doing most of the work to scrape data on each player's background and physical attributes.<br>\n",
    "> Example Overview Source (last name starting with a): https://www.basketball-reference.com/players/a/<br>\n",
    "> Example meta-data (Karim Abdul-Jabbar): https://www.basketball-reference.com/players/a/abdulka01.html<br>\n",
    "> For documentation on requests(): https://realpython.com/python-requests/<br>\n",
    "> For documentation on BeautifulSoup: https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Time Estimates:___ This is the most computationally-intensive function in the program, requiring many url requests in order to complete.<br>\n",
    ">*Without threading:* ~1hr<br>\n",
    ">*With threading:* ~15min<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metaInfoScraper\n",
      "   Start Time: 22:35:06.46\n",
      "    Threading inactivated\n",
      "['season', 'age', 'team_id', 'lg_id', 'pos', 'g', 'gs', 'mp', 'fg', 'fga', 'fg_pct', 'fg3', 'fg3a', 'fg3_pct', 'fg2', 'fg2a', 'fg2_pct', 'efg_pct', 'ft', 'fta', 'ft_pct', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts', 'DUMMY', 'trp_dbl']\n",
      "['season', 'age', 'team_id', 'lg_id', 'pos', 'g', 'gs', 'mp', 'fg', 'fga', 'fg_pct', 'fg3', 'fg3a', 'fg3_pct', 'fg2', 'fg2a', 'fg2_pct', 'efg_pct', 'ft', 'fta', 'ft_pct', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts', 'trp_dbl']\n",
      "['season', 'age', 'team_id', 'lg_id', 'pos', 'g', 'gs', 'mp', 'fg', 'fga', 'fg_pct', 'fg3', 'fg3a', 'fg3_pct', 'fg2', 'fg2a', 'fg2_pct', 'efg_pct', 'ft', 'fta', 'ft_pct', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts', 'DUMMY', 'trp_dbl']\n",
      "['season', 'age', 'team_id', 'lg_id', 'pos', 'g', 'gs', 'mp', 'fg', 'fga', 'fg_pct', 'fg3', 'fg3a', 'fg3_pct', 'fg2', 'fg2a', 'fg2_pct', 'efg_pct', 'ft', 'fta', 'ft_pct', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts', 'trp_dbl']\n",
      "['season', 'age', 'team_id', 'lg_id', 'pos', 'g', 'mp', 'fg_pct', 'avg_dist', 'DUMMY', 'pct_fga_fg2a', 'pct_fga_00_03', 'pct_fga_03_10', 'pct_fga_10_16', 'pct_fga_16_xx', 'pct_fga_fg3a', 'DUMMY', 'fg_pct_fg2a', 'fg_pct_00_03', 'fg_pct_03_10', 'fg_pct_10_16', 'fg_pct_16_xx', 'fg_pct_fg3a', 'DUMMY', 'pct_ast_fg2', 'pct_ast_fg3', 'DUMMY', 'pct_fga_dunk', 'fg_dunk', 'DUMMY', 'pct_fg3a_corner3', 'fg_pct_corner3', 'DUMMY', 'fg3a_heave', 'fg3_heave']\n",
      "['season', 'age', 'team_id', 'lg_id', 'pos', 'g', 'mp', 'fg_pct', 'avg_dist', 'pct_fga_fg2a', 'pct_fga_00_03', 'pct_fga_03_10', 'pct_fga_10_16', 'pct_fga_16_xx', 'pct_fga_fg3a', 'fg_pct_fg2a', 'fg_pct_00_03', 'fg_pct_03_10', 'fg_pct_10_16', 'fg_pct_16_xx', 'fg_pct_fg3a', 'pct_ast_fg2', 'pct_ast_fg3', 'pct_fga_dunk', 'fg_dunk', 'pct_fg3a_corner3', 'fg_pct_corner3', 'fg3a_heave', 'fg3_heave']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2f367705eb45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'    Threading inactivated'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murls_players\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mplayersHash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetaInfoScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayersHash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Parallel-Processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/GoogleDrive/My Drive/Projects/nba-prediction-algorithm/NBA-Prediction-Algorithms/basketball-reference-scraper/metaScraper.py\u001b[0m in \u001b[0;36mmetaInfoScraper\u001b[0;34m(url, playersHash)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;34m'''Running playerDataScraper to capture playerData'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mplayerData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayerHash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayerDataScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayerName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayerURL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;34m'''Creating Player object and inserting to playerHash'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/GoogleDrive/My Drive/Projects/nba-prediction-algorithm/NBA-Prediction-Algorithms/basketball-reference-scraper/playerScraper.py\u001b[0m in \u001b[0;36mplayerDataScraper\u001b[0;34m(playerName, playerURL)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;34m'pct_fga_03_10'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pct_fga_10_16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pct_fga_16_xx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fg3a_pct_fga'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fg2_pct'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fg_pct_00_03'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fg_pct_03_10'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     'fg_pct_10_16', 'fg_pct_16_xx', 'fg3_pct', 'fg2_pct_ast', 'pct_fg2_dunk', 'fg2_dunk', 'fg3_pct_ast', 'pct_fg3a_corner', 'fg3_pct_corner', 'fg3a_heave', 'fg3_heave']\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mplayerHash\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'regular_season'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shooting'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtableScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshooting_allFields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayerName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'all_shooting'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'div'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mplayerHash\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'playoffs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shooting'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtableScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshooting_allFields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayerName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'all_playoffs_shooting'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'div'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/GoogleDrive/My Drive/Projects/nba-prediction-algorithm/NBA-Prediction-Algorithms/basketball-reference-scraper/tableScraper.py\u001b[0m in \u001b[0;36mtableScraper\u001b[0;34m(allFields, playerName, playerSoup, statType, statTag)\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0mstatsObject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdvancedStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;34m'shooting'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstatType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                     \u001b[0mstatsObject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShootingStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;34m'pbp'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstatType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0mstatsObject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlayByPlayStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/GoogleDrive/My Drive/Projects/nba-prediction-algorithm/NBA-Prediction-Algorithms/basketball-reference-scraper/PlayerStatObjects.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, SeasonData)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mfg2_pct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg_pct_00_03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg_pct_03_10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg_pct_10_16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg_pct_16_xx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg3_pct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mfg2_pct_ast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpct_fg2_dunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg2_dunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg3_pct_ast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpct_fg3a_corner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mfg3_pct_corner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg3a_heave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg3_heave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeasonData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 30)"
     ]
    }
   ],
   "source": [
    "from metaScraper import metaInfoScraper\n",
    "\n",
    "playersHash = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n",
    "\n",
    "urls_players = []\n",
    "for letter in ascii_lowercase:\n",
    "    url = 'https://www.basketball-reference.com/players/' + letter\n",
    "    urls_players.append(url)\n",
    "\n",
    "start_datetime = datetime.datetime.now()\n",
    "start_time = time.time()\n",
    "print ('metaInfoScraper')\n",
    "print ('   Start Time:', str(start_datetime.time())[:11])\n",
    "\n",
    "'''\n",
    "## Thread flag decides whether you want to use parallel processing or standard\n",
    "'''\n",
    "thread_flag = False\n",
    "\n",
    "# Sequential-Processing\n",
    "if thread_flag == False:\n",
    "    print('    Threading inactivated')\n",
    "    for url in urls_players:\n",
    "        playersHash = metaInfoScraper(url, playersHash)\n",
    "        break\n",
    "# Parallel-Processing\n",
    "else:\n",
    "    print('    Threading activated')\n",
    "    threads = []\n",
    "    for url in urls_players:\n",
    "        thread = threading.Thread(target=metaInfoScraper, args=(url,playersHash,))\n",
    "        threads += [thread]\n",
    "        thread.start()\n",
    "    for thread in threads:\n",
    "        thread.join() # makes sure that the main program waits until all threads have terminated\n",
    "end_time = time.time()\n",
    "print ('   Run Time:', str((end_time - start_time)/60)[:6], 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Volumes/GoogleDrive/My Drive/Projects/nba-prediction-algorithm/NBA-Prediction-Algorithms/basketball-reference-scraper/PlayerStatObjects.py\u001b[0m(148)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    146 \u001b[0;31m        \u001b[0mfg2_pct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg_pct_00_03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg_pct_03_10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg_pct_10_16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg_pct_16_xx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg3_pct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    147 \u001b[0;31m        \u001b[0mfg2_pct_ast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpct_fg2_dunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg2_dunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg3_pct_ast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpct_fg3a_corner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 148 \u001b[0;31m        \u001b[0mfg3_pct_corner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg3a_heave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfg3_heave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeasonData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    149 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    150 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  print(SeasonData)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mahmoud Abdul-Rauf', '1996-97', '27', 'SAC', 'NBA', 'PG', '75', '2131', '.445', '17.7', '', '.734', '.067', '.026', '.133', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '.508', '.266', '', '.468', '.484', '.375', '.423', '.482', '.382', '', '.580', '.734', '', '.000', '0', '', '.045', '.364', '', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Scraping Game Data\n",
    "### Game-logs and team statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seasonScraper\n",
    "importlib.reload(seasonScraper)\n",
    "from teamsScraper import teamsScraper\n",
    "\n",
    "seasonsHash = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n",
    "\n",
    "YEAR_START = 1947\n",
    "YEAR_CURRENT = 2021\n",
    "LEAGUES = ['NBA', 'ABA']\n",
    "\n",
    "urls_seasons = []\n",
    "for year in range(YEAR_START, YEAR_CURRENT):\n",
    "    # Easiest solution for exception years in which both the NBA and ABA existed (i.e. 1967-1976)\n",
    "    stem = 'https://www.basketball-reference.com/leagues/'\n",
    "    for league in LEAGUES:\n",
    "        # Example url = https://www.basketball-reference.com/leagues/NBA_2020.html\n",
    "        url = stem + league + '_'+ str(year) + '.html'\n",
    "        urls_seasons.append(url)\n",
    "\n",
    "start_datetime = datetime.datetime.now()\n",
    "start_time = time.time()\n",
    "print ('seasonScraper')\n",
    "print ('   Start Time:', str(start_datetime.time())[:11])\n",
    "\n",
    "'''\n",
    "Thread flag decides whether you want to\n",
    "use parallel processing or standard\n",
    "'''\n",
    "thread_flag = False\n",
    "\n",
    "'''Dictionary of all NBA teams'''\n",
    "teamsHash = teamsScraper() \n",
    "\n",
    "# Sequential-Processing\n",
    "if thread_flag == False:\n",
    "    print('    Threading inactivated')\n",
    "    for url in urls_seasons:\n",
    "        league = url[-13:-10]\n",
    "        year = url[-9:-5]\n",
    "        seasonsHash[league][year] = seasonScraper.seasonInfoScraper(url, seasonsHash)\n",
    "        print(f'      Scraping NBA Season: {year}\\r', end=\"\")\n",
    "    print()\n",
    "# Parallel-Processing\n",
    "else:\n",
    "    print('    Threading activated')\n",
    "    threads = []\n",
    "    for url in urls_seasons:\n",
    "        thread = threading.Thread(target=seasonInfoScraper, args=(url,seasonsHash,))\n",
    "        threads += [thread]\n",
    "        thread.start()\n",
    "    for thread in threads:\n",
    "        thread.join() # makes sure that the main program waits until all threads have terminated\n",
    "end_time = time.time()\n",
    "print ('   Run Time:', str((end_time - start_time)/60)[:6], 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Data Organization\n",
    "To help us understand how all the data is organized, here's a visual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(playersHash['Kareem Abdul-Jabbar']['stats']['regular_season'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Meta-Data Analysis\n",
    "Now that we've scraped all the meta-info on each player, we can start running analyses.\n",
    "\n",
    "Below, a few simple analyses are included to help you get started. The first set of graphs examine height distribution (left), weight distribution (middle), and shooting handedness (right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def metaPlot():\n",
    "    height_list = []; weight_list = []\n",
    "    rightCount = 0; leftCount = 0; noHandCount = 0\n",
    "    for player in playersHash.keys():\n",
    "        try:\n",
    "            height_list.append(int(playersHash[player]['meta_info'].height))\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            weight_list.append(int(playersHash[player]['meta_info'].weight))\n",
    "        except:\n",
    "            pass\n",
    "        if playersHash[player]['meta_info'].shootingHand == 'Right':\n",
    "            rightCount+=1\n",
    "        elif playersHash[player]['meta_info'].shootingHand == 'Left':\n",
    "            leftCount+=1\n",
    "        else:\n",
    "            noHandCount+=1\n",
    "\n",
    "    #Plot Height Distribution (1, Left)\n",
    "    f, ax = plt.subplots(1,3)\n",
    "    #Sets default plot size\n",
    "    plt.rcParams['figure.figsize'] = (10,8)\n",
    "    n1, bins1, patches1 = ax[0].hist(height_list, bins=20, density=True, histtype='bar', ec='black')\n",
    "    #Converting y-axis labels from decimals to percents\n",
    "    y_vals = ax[0].get_yticks(); ax[0].set_yticklabels(['{:3.1f}%'.format(y*100) for y in y_vals])\n",
    "    #Converting x-axis labels from inches back to feet\n",
    "    xticks1 = ['5-0', '5-6', '6-0', '6-6', '7-0', '7-6', '8-0']\n",
    "    ax[0].set_xticks([60, 66, 72, 78, 84, 90, 96])\n",
    "    ax[0].set_xticklabels(xticks1)\n",
    "    ax[0].set_xlim([56,100])\n",
    "    ax[0].set_xlabel('Height', fontweight='bold', labelpad=10)\n",
    "    ax[0].set_ylabel('Percent of Players', fontweight='bold', labelpad=10)\n",
    "\n",
    "    #Plot Weight Distribution (1, Middle)\n",
    "    ax[1].hist(weight_list, bins='auto', density=True, histtype='bar', ec='black')\n",
    "    y_vals = ax[1].get_yticks()\n",
    "    ax[1].set_yticklabels(['{:3.1f}%'.format(y*100) for y in y_vals])\n",
    "    xticks2 = ['150', '180', '210', '240', '270', '300', '330']\n",
    "    ax[1].set_xticks([150, 180, 210, 240, 270, 300, 330])\n",
    "    ax[1].set_xticklabels(xticks2)\n",
    "    ax[1].set_xlim([120,360])\n",
    "    ax[1].set_xlabel('Weight', fontweight='bold', labelpad=10)\n",
    "    ax[1].set_ylabel('Percent of Players', fontweight='bold', labelpad=10)\n",
    "\n",
    "    #Plot Shooting Handedness (1, Right)\n",
    "    ax[2].bar([1,2,3], [rightCount,leftCount,noHandCount], ec='black')\n",
    "    ax[2].set_xticks([1,2,3]); ax[2].set_xticklabels(['Right','Left', 'N/A'])\n",
    "    ax[2].set_xlabel('Shooting Handedness', fontweight='bold', labelpad=10)\n",
    "    ax[2].set_ylabel('Number of Players', fontweight='bold', labelpad=10)\n",
    "    \n",
    "    plt.tight_layout(pad=0.05, w_pad=4, h_pad=1.0)\n",
    "    f.set_size_inches(18.5, 10.5, forward=True)\n",
    "    plt.show()\n",
    "        \n",
    "metaPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geographyPlot():\n",
    "    stateList = []; countryList = []\n",
    "    for player in playersHash.keys():\n",
    "        stateList.append(playersHash[player]['meta_info'].birthState)\n",
    "        countryList.append(playersHash[player]['meta_info'].birthCountry)\n",
    "    #stateList contains all players born in the US\n",
    "    stateList = filter(lambda x: x != '', stateList)\n",
    "    stateHash = dict(Counter(stateList))\n",
    "    stateHash = OrderedDict(sorted(stateHash.items(), reverse=True, key=lambda t: t[1]))\n",
    "    #countryList contains all players born in ex-US\n",
    "    countryList = filter(lambda x: x != 'United States of America', countryList)\n",
    "    countryList = filter(lambda x: x != '', countryList)\n",
    "    countryHash = dict(Counter(countryList))\n",
    "    countryHash = OrderedDict(sorted(countryHash.items(), reverse=True, key=lambda t: t[1]))\n",
    "\n",
    "\n",
    "    #Plot Birth State of US-Born Players (2)\n",
    "    f, ax = plt.subplots(1)\n",
    "    stateList = stateHash.keys(); stateVals = stateHash.values()\n",
    "    ax.bar(np.arange(len(stateList)), stateVals, ec='black')\n",
    "    ax.set_xticks(np.arange(len(stateList)))\n",
    "    ax.set_xticklabels(stateList, rotation=90, ha='right', fontsize=7)\n",
    "    ax.set_xlabel('US State of Birth', fontweight='bold', labelpad=10)\n",
    "    ax.set_ylabel('Number of Players', fontweight='bold', labelpad=10)\n",
    "    plt.show();\n",
    "\n",
    "    #Plot Birth Countries of non-US-Born Players (3)\n",
    "    f, ax = plt.subplots(1)\n",
    "    countryList = countryHash.keys(); countryVals = countryHash.values()\n",
    "    ax.bar(np.arange(len(countryList)), countryVals, ec='black')\n",
    "    ax.set_xticks(np.arange(len(countryList)))\n",
    "    ax.set_xticklabels(countryList, rotation=90, ha='right', fontsize=7)\n",
    "    ax.set_xlabel('Country of Birth', fontweight='bold', labelpad=10)\n",
    "    ax.set_ylabel('Number of Players', fontweight='bold', labelpad=10)\n",
    "    \n",
    "    f.set_size_inches(18.5, 10.5, forward=True)\n",
    "    plt.show()\n",
    "    \n",
    "geographyPlot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Creating Databases\n",
    "Pandas databases are a powerful tool to query large amounts of data, as we will be doing here. For that reason, we are going to insert all of the data scraped above into a Pandas database. The below code will take player overview data from playerHash and insert it into player_df<br>\n",
    ">For documentation on pandas: https://pypi.org/project/pandas/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Scraping All Players Table Statistics (perGame, total, per36, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perGameScraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Generation\n",
    "\n",
    "Just like with playerTable, we're going to generate SQLite tables for all of the other tables we've scraped, in order to quickly access information and generate immediate queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Queries (Simple)\n",
    "\n",
    "The following are example queries we can make across all of the generated tables. As can be seen below, the structure of each SQLite table allows for immense flexibility and speed gains as compared to looking at the website itself. We will utilize this structure for more specific trend-, team-, and era- related investigations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
